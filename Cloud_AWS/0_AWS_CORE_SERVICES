NETFLIX CONFIGURATION USING AWS - youtube
SINGLE LINE ABOUT EACH AND EVRY TOPIC and introductory vedios
Deploy a static website in aws s3 and ec2 - webserver
Deploy a wordpress blog - youtube https://www.youtube.com/embed/qKljYgi2lQ0?rel=0&hd=1
STS - https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html
ENI in VPC : https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#scenarios-enis
A secondary ENI can be added to an instance. While primary ENIs cannot be detached from an instance, secondary ENIs can be detached and attached to a different instance

what is an API and what are Rest API calls .
s3 storage classes - availability and durability , capacities -
cloud trail vs cloud watch - multiple questions
Database : Amazon RDS - Amazon DynamoDB
update yaml info in 1_Cloud_aws-intro at the bottom

WHAT IS SERVERLESS APPLICATION
===================================


##################################################################################################################
##################################################################################################################
ANALYTICS :
##################################################################################################################
##################################################################################################################

1. AMAZON APP FLOW :  https://www.youtube.com/watch?v=USzaWjjjOJI
Bidirectional data transfer from SAAS Applications To AWS
Amazon App Flow is a fully-managed integration service that enables you to securely exchange data between software as a service (SaaS) applications, such as Salesforce, Slack and AWS services, such as Amazon Simple Storage Service (Amazon S3) and Amazon Redshift.
For example, you can ingest contact records from Salesforce to Amazon Redshift or pull support tickets from Zendesk to an Amazon S3 bucket.

2. AMAZON ATHENA :  https://www.youtube.com/watch?v=M5ptG0YaqAs&t=1s
Amazon Athena is an interactive query service that makes it easy to analyze data directly in Amazon Simple Storage Service (Amazon S3) using standard SQL.
With a few actions in the AWS Management Console, you can point Athena at your data stored in Amazon S3 and begin using standard SQL to run ad-hoc queries and get results in seconds.
Athena is serverless, so there is no infrastructure to set up or manage, and you pay only for the queries you run.
Athena scales automatically—running queries in parallel—so results are fast, even with large datasets and complex queries.
You can query structured , unstructured and semi structured data as well. Examples include CSV, JSON, or columnar data formats such as Apache Parquet and Apache ORC.
You can then store results from queries directly into another bucket in S3 or download then to local.

3. AMAZON CLOUD-SEARCH :  https://www.youtube.com/watch?v=gpG16MFnEH8&t=14s
With Amazon CloudSearch, you can quickly add rich search capabilities to your website or application.
You don't need to become a search expert or worry about hardware provisioning, setup, and maintenance.
With a few clicks in the AWS Management Console, you can create a search domain and upload the data that you want to make searchable, and Amazon CloudSearch will automatically provision the required resources and deploy a highly tuned search index.
You can easily change your search parameters, fine tune search relevance, and apply new settings at any time.
      Free text, Boolean, and Faceted search - Autocomplete suggestions - Customizable relevance ranking and query-time rank expressions - Field weighting
      Geospatial search - Highlighting - Support for 34 languages

4. AWS DATA EXCHANGE : https://www.youtube.com/watch?v=Lu9QVJ0Rml4&t=26s
AWS Data Exchange is a service that makes it easy for AWS customers to securely exchange file-based data sets in the AWS Cloud.
As a subscriber, you can find and subscribe to hundreds of products from qualified data providers.
Then, you can quickly download the data set or copy it to Amazon S3 for use across a variety of AWS analytics and machine learning service.
Providers in AWS Data Exchange have a secure, transparent, and reliable channel to reach AWS customers and grant existing customers their subscriptions more efficiently.
To promote a safe, secure, and trustworthy service for everyone, AWS Data Exchange scans all data published by providers before it is made available to subscribers. If AWS detects malware, the affected asset is removed.
Used by colleges, hospitals , scientists to get data from various data lakes .

5. AWS DATA PIPELINE :
AWS Data Pipeline is a web service that you can use to automate the movement and transformation of data.
With AWS Data Pipeline, you can define data-driven workflows, so that tasks can be dependent on the successful completion of previous tasks.
You define the parameters of your data transformations and AWS Data Pipeline enforces the logic that you've set up.
A pipeline schedules and runs tasks by creating Amazon EC2 instances to perform the defined work activities.
You upload your pipeline definition to the pipeline, and then activate the pipeline.
Task Runner polls for tasks and then performs those tasks. For example, Task Runner could copy logfiles to Amazon S3 and launch Amazon EMR clusters.
Task Runner is installed and runs automatically on resources created by your pipeline definitions.

6. AMAZON ELASTIC-SEARCH SERVICE : https://www.youtube.com/watch?v=4Zw1IOxW-oA&t=26s
Used to analyse and get real time  insights on machine generated data at a peta byte scale. Supports Log stash , Kibana etc ;
Amazon Elasticsearch Service (Amazon ES) is a managed service that makes it easy to deploy, operate, and scale Elasticsearch clusters in the AWS Cloud.
Elasticsearch is a popular open-source search and analytics engine for use cases such as log analytics, real-time application monitoring, and click stream analysis.
With Amazon ES, you get direct access to the Elasticsearch APIs; existing code and applications work seamlessly with the service.

7. AMAZON EMR : https://www.youtube.com/watch?v=QuwaBOESGiU
APACHE SPARK - APACHE HADOOP - CLUSTERS - SPARK  --> Maintaining Hadoop and Spark is costly so EMR does this for  us .
Amazon EMR is a managed cluster platform that simplifies running big data frameworks, such as Apache Hadoop and Apache Spark, on AWS to process and analyze vast amounts of data.
By using these frameworks and related open-source projects, such as Apache Hive and Apache Pig, you can process data for analytics purposes and business intelligence workloads.
The central component of Amazon EMR is the cluster. A cluster is a collection of Amazon Elastic Compute Cloud (Amazon EC2) instances.
Each instance in the cluster is called a node. Each node has a role within the cluster, referred to as the node type.
Amazon EMR also installs different software components on each node type, giving each node a role in a distributed application like Apache Hadoop.
Master node - Core Node - Task Node


8. AWS GLUE : https://www.youtube.com/watch?v=oAxvd547kMU&t=28s
AWS Glue is a fully managed ETL (extract, transform, and load) service that makes it simple and cost-effective to categorize your data, clean it, enrich it, and move it reliably between various data stores and data streams.
It is used to combine data [ Prepare a data lake ] from various sources and clean , normalize and prepare data to one common syntax and save to S3.
It uses other AWS services to orchestrate your ETL jobs to build data warehouses and data lakes and generate output streams.
AWS Glue calls API operations to transform your data, create runtime logs, store your job logic, and create notifications to help you monitor your job runs.

9. AMAZON KINESIS : https://www.youtube.com/watch?v=MbEfiX4sMXc&t=19s      &&    https://www.youtube.com/watch?v=07iZOEl0knc&t=29s
Save data - logs - audio - video -> live stream -> analyze -> take action
    Kinesis Streams -> low latency streaming of data / video
    Kinesis Analytics -> perform real time analytics using SQL
    Kinesis Firehose : Load streams into S3, Elastic Search etc;

Amazon Kinesis Video Streams is a fully managed AWS service that you can use to stream live video from devices to the AWS Cloud, or build applications for real-time video processing or batch-oriented video analytics.
Kinesis Video Streams isn't just storage for video data. You can use it to watch your video streams in real time as they are received in the cloud.
You can use Kinesis Video Streams to capture massive amounts of live video data from millions of sources, including smartphones, security cameras, webcams, cameras embedded in cars, drones, andother sources.
You can also send non-video time-serialized data such as audio data, thermal imagery, depth data, RADAR data, and use kinesis to process these at a later Time.
you can stream video from a computer's webcam using the GStreamer  library, or from a camera on your network using RTSP.
You can also configure your Kinesis video stream to durably store media data for the specified retention period.
Kinesis Video Streams automatically stores this data and encrypts it at rest.
--> logs from mobile applications - logs from e-commers purchases - information from social media - satellite data - audio - video - spy cams - security cams etc;

10. AWS LAKE FORMATION :
The data lake is your persistent data that is stored in Amazon S3 and managed by Lake Formation using a Data Catalog.
The Data Catalog is your persistent metadata store. It is a managed service that lets you store, annotate, and share metadata in the AWS Cloud.
Metadata about data sources and targets is in the form of databases and tables.
AWS Lake Formation is a fully managed service that makes it easier for you to build, secure, and manage data lakes.
Lake Formation simplifies and automates many of the complex manual steps that are usually required to create data lakes.
These steps include collecting, cleansing, moving, and cataloging data, and securely making that data available for analytics and machine learning.
You point Lake Formation at your data sources, and Lake Formation crawls those sources and moves the data into your new Amazon Simple Storage Service (Amazon S3) data lake.
After the data is securely stored in the data lake, users can access the data through their choice of analytics services, including Amazon Athena, Amazon Redshift, and Amazon EMR.

11. AMAZON  MSK : Managed Streaming for Apache Kafka
Amazon Managed Streaming for Apache Kafka (Amazon MSK) is a fully managed service that enables you to build and run applications that use Apache Kafka to process streaming data.
Amazon MSK provides the control-plane operations, such as those for creating, updating, and deleting clusters.
It lets you use Apache Kafka data-plane operations, such as those for producing and consuming data. It runs open-source versions of Apache Kafka.

12. AMAZON QUICKSIGHT : https://www.youtube.com/watch?v=2V1bHRLRG-w&t=8s
Amazon QuickSight is a cloud-scale business intelligence (BI) service that you can use to deliver easy-to-understand insights to the people who you work with, wherever they are.
It connects to your data in the cloud and combines data from many different sources.
In a single data dashboard, QuickSight can include AWS data, third-party data, big data, spreadsheet data, SaaS data, B2B data, and more.
Securely push these dashboards to customers. Used to forecast future results and take decisions.

13. AMAZON REDSHIFT : https://www.youtube.com/watch?v=_qKm6o1zK3U&t=9s
Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. An Amazon Redshift data warehouse is a collection of computing resources called nodes, which are organized into a group called a cluster.
Each cluster runs an Amazon Redshift engine and contains one or more databases.
Redshift lets you easily save the results of your queries back to your S3 data lake using open formats, like Apache Parquet, so that you can do additional analytics from other analytics services like Amazon EMR, Amazon Athena, and Amazon SageMaker.


##################################################################################################################
##################################################################################################################
COMPUTE  :
##################################################################################################################
##################################################################################################################

1. ELASTIC COMPUTE CLOUD : < Self - Explanatory // Has a separate chapter >
Amazon Elastic Compute Cloud (Amazon EC2) provides scalable computing capacity in the Amazon Web Services (AWS) Cloud.
Using Amazon EC2 eliminates your need to invest in hardware up front, so you can develop and deploy applications faster.
You can use Amazon EC2 to launch as many or as few virtual servers as you need, configure security and networking, and manage storage.
Amazon EC2 enables you to scale up or down to handle changes in requirements or spikes in popularity, reducing your need to forecast traffic.

2. AWS BATCH : https://www.youtube.com/watch?v=j_iI1DzSi5g      &&   https://www.youtube.com/watch?v=T4aAWrGHmxQ&t=29s
AWS Batch enables you to run batch computing workloads on the AWS Cloud.
Batch computing is a common way for developers, scientists, and engineers to access large amounts of compute resources.
AWS Batch removes the undifferentiated heavy lifting of configuring and managing the required infrastructure.
As a fully managed service, AWS Batch helps you to run batch computing workloads of any scale.
AWS Batch automatically provisions compute resources and optimizes the workload distribution based on the quantity and scale of the workloads.
With AWS Batch, there is no need to install or manage batch computing software, which allows you to focus on analysing results and solving problems.
After a compute environment is up and associated with a job queue, you can define job definitions that specify which Docker container images to run your jobs.
  --> Break work into bathes and tell AWS which batch needs which resources are required and when to execute a batch

3. AWS ELASTI BEANSTALK : < Self - Explanatory // Has a separate chapter > https://www.youtube.com/watch?v=SrwxAScdyT0&t=28s
--> Focus on your code --> Write it --> Upload it -->  AWS takes care of required resources .
With AWS Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without worrying about the infrastructure that runs those applications.
AWS Elastic Beanstalk reduces management complexity without restricting choice or control.
You simply upload your application, and AWS Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.

4. AMAZON EC2 IMAGE BUILDER : https://www.youtube.com/watch?v=K5d2VdByohs&t=151s
It's a fully-managed AWS service that makes it easier to automate the creation, management, and deployment of customized, secure, and up-to-date “golden” server images that are pre-installed and pre-configured with software and settings to meet specific IT standards.
Crete a custom image based on required parameters and share the AMI across accounts or for instances in your account .

5. AWS LAMBDA : < Self - Explanatory // Has a separate chapter >
--> Do something in response to events such as an api call / SNS / a data change in S3 /etc ;
With AWS Lambda, you can run code without provisioning or managing servers.
You pay only for the compute time that you consume—there’s no charge when your code isn’t running.
You can run code for virtually any type of application or backend service—all with zero administration.
Just upload your code and Lambda takes care of everything required to run and scale your code with high availability.
You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app.

6. AWS LAUNCH WIZARD :
--> Used by enterprise applications .
AWS Launch Wizard reduces the time it takes to deploy application and domain-controller solutions to the cloud by providing easy step-by-step guidance.
You input your application or domain controller requirements, and AWS Launch Wizard identifies the right AWS resources to deploy and run your solution.
AWS Launch Wizard provides an estimated cost of deployment, and gives you the ability to modify your resources and instantly view the updated cost assessment.
When you approve, AWS Launch Wizard provisions and configures the selected resources in a few hours to create fully-functioning, production-ready applications or domain controllers. It also creates custom AWS CloudFormation templates, which can be reused and customized for subsequent deployments.

7. AMAZON LIGHT SAIL : https://www.youtube.com/watch?v=wzhTAwRbdXw
--> Deploying a word press site etc ;
Amazon Lightsail helps developers get started using AWS to build websites or web applications.
It includes the features that you need to launch your project: instances (virtual private servers), managed databases, SSD-based block storage, static IP addresses, load balancers, content delivery network (CDN) distributions, DNS management of registered domains, and snapshots (backups).
These features are all available for a low, predictable monthly price.

8. AWS OUTPOSTS : https://www.youtube.com/watch?v=ppG2FFB0mMQ&t=9s
--> Even though we can use cloud , some applications still need to be on premises for latency issues . Hence OUTPOSTS.
    So instead of changing applications to meet both cloud and on premises apps , we can use same API's to access resources in both.
    AWS Technician comes and set up all the resources needed to connect resources in cloud and resources in on-premises.
An Outpost is a pool of AWS compute and storage capacity deployed at a customer site.
AWS Outposts brings native AWS services, infrastructure, and operating models to virtually any data center, co-location space, or on-premises facility.
You can use the same services, tools, and partner solutions to develop for the cloud and on premises .

9. AWS PARALLEL CLUSTER : HPC // 1000's of CPU or GPU.   https://www.youtube.com/watch?v=r4RxT-IMtFY
AWS Parallel Cluster is an AWS supported open source cluster management tool that helps you to deploy and manage high performance computing (HPC) clusters in the AWS Cloud.
You can use AWSParallelCluster with batch schedulers, such as AWS Batch and Slurm.
AWS Parallel Cluster facilitates quick start proof of concept deployments and production deployments.
You can also build higher level workflows, such as a genomics portal that automates an entire DNA sequencing workflow, on top of AWSParallelCluster.

10. AWS SERVERLESS APPLICATION MODEL :
The AWS Serverless Application Model (AWS SAM) is an open-source framework that you can use to buildserverless applications on AWS.
You can use AWS SAM to define your serverless applications.
It is an extension of CLOUD FORMATION

11. AWS SERVERLESS APPLICATION REPOSITORY :
The AWS Serverless Application Repository is a managed repository for serverless applications.
It enables teams, organizations, and individual developers to find, deploy, publish, share, store, and easily assemble serverless architectures.
Using SAM from above , we can publish and deploy applications to the public or to our team.

12. AWS WAVE LENGTH : To fully utilize 5G capabilities . // https://www.youtube.com/watch?v=EhMqwPqPzcY&t=6s
AWS Wavelength allows developers to build applications that deliver ultra-low latencies to mobile devices and end users.
Wavelength deploys standard AWS compute and storage services to the edge of telecommunication carriers' 5G networks.
Developers can extend an Amazon Virtual Private Cloud (VPC) to one or more Wavelength Zones.
Then use AWS resources like Amazon Elastic Compute Cloud (EC2) instances to run applications that require ultra-low latency and a connection to AWS services in the Region.
To help 5G --> Gaming experience - smart cities - robotics - autonomous driving cars




Amazon Lightsail
AWS Outposts
AWS ParallelCluster
AWS Serverless Application Model (AWS SAM)
AWS Serverless Application Repository
AWS Wavelength

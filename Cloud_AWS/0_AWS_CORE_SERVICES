NETFLIX CONFIGURATION USING AWS - youtube
SINGLE LINE ABOUT EACH AND EVRY TOPIC and introductory vedios
Deploy a static website in aws s3 and ec2 - webserver
Deploy a wordpress blog - youtube https://www.youtube.com/embed/qKljYgi2lQ0?rel=0&hd=1
STS - https://docs.aws.amazon.com/STS/latest/APIReference/welcome.html
ENI in VPC : https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#scenarios-enis
A secondary ENI can be added to an instance. While primary ENIs cannot be detached from an instance, secondary ENIs can be detached and attached to a different instance

what is an API and what are Rest API calls .
s3 storage classes - availability and durability , capacities -
cloud trail vs cloud watch - multiple questions
Database : Amazon RDS - Amazon DynamoDB
update yaml info in 1_Cloud_aws-intro at the bottom
glacier vs glacier deep archive
replicate data across regions

===================================

TOTAL AVAILABLE SERVICE CATEGORIES  IN AWS : (As of January 2021)
====================================================================
This page contains a detailed description of what the services do in each of the categories .
Topics having a higher importance have individual chapters written after them.
Recommended to View the YouTube Video , link provided beside the topic heading before going through the material.

-------------------------------------------------------------------------------------------------------------------
SERVICES COVERED :                                                SERVICES NOT COVERED :
-------------------------------------------------------------------------------------------------------------------
Analytics                                                         AR & VR
Application Integration                                           Blockchain
Billing & Cost Management                                         Front-End Web & Mobile
Business Applications                                             Game Development
Compute                                                           Internet of Things (IoT)
Containers                                                        Machine Learning
Cryptography & PKI                                                Media Services
Customer Enablement Services                                      Quantum Computing
Customer Engagement                                               Robotics
Data Base                                                         Satellite
Developer Tools
End User Computing
Management & Governance
Migration & Transfer
Networking & Content Delivery
Security, Identity, & Compliance
Storage



##################################################################################################################
##################################################################################################################
ANALYTICS :
##################################################################################################################
##################################################################################################################

1. AMAZON APP FLOW :  https://www.youtube.com/watch?v=USzaWjjjOJI
Bidirectional data transfer from SAAS Applications To AWS
Amazon App Flow is a fully-managed integration service that enables you to securely exchange data between software as a service (SaaS) applications, such as Salesforce, Slack and AWS services, such as Amazon Simple Storage Service (Amazon S3) and Amazon Redshift.
For example, you can ingest contact records from Salesforce to Amazon Redshift or pull support tickets from Zendesk to an Amazon S3 bucket.

2. AMAZON ATHENA :  https://www.youtube.com/watch?v=M5ptG0YaqAs&t=1s
Amazon Athena is an interactive query service that makes it easy to analyze data directly in Amazon Simple Storage Service (Amazon S3) using standard SQL.
With a few actions in the AWS Management Console, you can point Athena at your data stored in Amazon S3 and begin using standard SQL to run ad-hoc queries and get results in seconds.
Athena is serverless, so there is no infrastructure to set up or manage, and you pay only for the queries you run.
Athena scales automatically—running queries in parallel—so results are fast, even with large datasets and complex queries.
You can query structured , unstructured and semi structured data as well. Examples include CSV, JSON, or columnar data formats such as Apache Parquet and Apache ORC.
You can then store results from queries directly into another bucket in S3 or download then to local.

3. AMAZON CLOUD-SEARCH :  https://www.youtube.com/watch?v=gpG16MFnEH8&t=14s
With Amazon CloudSearch, you can quickly add rich search capabilities to your website or application.
You don't need to become a search expert or worry about hardware provisioning, setup, and maintenance.
With a few clicks in the AWS Management Console, you can create a search domain and upload the data that you want to make searchable, and Amazon CloudSearch will automatically provision the required resources and deploy a highly tuned search index.
You can easily change your search parameters, fine tune search relevance, and apply new settings at any time.
      Free text, Boolean, and Faceted search - Autocomplete suggestions - Customizable relevance ranking and query-time rank expressions - Field weighting
      Geospatial search - Highlighting - Support for 34 languages

4. AWS DATA EXCHANGE : https://www.youtube.com/watch?v=Lu9QVJ0Rml4&t=26s
AWS Data Exchange is a service that makes it easy for AWS customers to securely exchange file-based data sets in the AWS Cloud.
As a subscriber, you can find and subscribe to hundreds of products from qualified data providers.
Then, you can quickly download the data set or copy it to Amazon S3 for use across a variety of AWS analytics and machine learning service.
Providers in AWS Data Exchange have a secure, transparent, and reliable channel to reach AWS customers and grant existing customers their subscriptions more efficiently.
To promote a safe, secure, and trustworthy service for everyone, AWS Data Exchange scans all data published by providers before it is made available to subscribers. If AWS detects malware, the affected asset is removed.
Used by colleges, hospitals , scientists to get data from various data lakes .

5. AWS DATA PIPELINE :
AWS Data Pipeline is a web service that you can use to automate the movement and transformation of data.
With AWS Data Pipeline, you can define data-driven workflows, so that tasks can be dependent on the successful completion of previous tasks.
You define the parameters of your data transformations and AWS Data Pipeline enforces the logic that you've set up.
A pipeline schedules and runs tasks by creating Amazon EC2 instances to perform the defined work activities.
You upload your pipeline definition to the pipeline, and then activate the pipeline.
Task Runner polls for tasks and then performs those tasks. For example, Task Runner could copy logfiles to Amazon S3 and launch Amazon EMR clusters.
Task Runner is installed and runs automatically on resources created by your pipeline definitions.

6. AMAZON ELASTIC-SEARCH SERVICE : https://www.youtube.com/watch?v=4Zw1IOxW-oA&t=26s
Used to analyse and get real time  insights on machine generated data at a peta byte scale. Supports Log stash , Kibana etc ;
Amazon Elasticsearch Service (Amazon ES) is a managed service that makes it easy to deploy, operate, and scale Elasticsearch clusters in the AWS Cloud.
Elasticsearch is a popular open-source search and analytics engine for use cases such as log analytics, real-time application monitoring, and click stream analysis.
With Amazon ES, you get direct access to the Elasticsearch APIs; existing code and applications work seamlessly with the service.

7. AMAZON EMR : https://www.youtube.com/watch?v=QuwaBOESGiU
APACHE SPARK - APACHE HADOOP - CLUSTERS - SPARK  --> Maintaining Hadoop and Spark is costly so EMR does this for  us .
Amazon EMR is a managed cluster platform that simplifies running big data frameworks, such as Apache Hadoop and Apache Spark, on AWS to process and analyze vast amounts of data.
By using these frameworks and related open-source projects, such as Apache Hive and Apache Pig, you can process data for analytics purposes and business intelligence workloads.
The central component of Amazon EMR is the cluster. A cluster is a collection of Amazon Elastic Compute Cloud (Amazon EC2) instances.
Each instance in the cluster is called a node. Each node has a role within the cluster, referred to as the node type.
Amazon EMR also installs different software components on each node type, giving each node a role in a distributed application like Apache Hadoop.
Master node - Core Node - Task Node


8. AWS GLUE : https://www.youtube.com/watch?v=oAxvd547kMU&t=28s
AWS Glue is a fully managed ETL (extract, transform, and load) service that makes it simple and cost-effective to categorize your data, clean it, enrich it, and move it reliably between various data stores and data streams.
It is used to combine data [ Prepare a data lake ] from various sources and clean , normalize and prepare data to one common syntax and save to S3.
It uses other AWS services to orchestrate your ETL jobs to build data warehouses and data lakes and generate output streams.
AWS Glue calls API operations to transform your data, create runtime logs, store your job logic, and create notifications to help you monitor your job runs.

9. AMAZON KINESIS : https://www.youtube.com/watch?v=MbEfiX4sMXc&t=19s      &&    https://www.youtube.com/watch?v=07iZOEl0knc&t=29s
Save data - logs - audio - video -> live stream -> analyze -> take action
    Kinesis Streams -> low latency streaming of data / video
    Kinesis Analytics -> perform real time analytics using SQL
    Kinesis Firehose : Load streams into S3, Elastic Search etc;

Amazon Kinesis Video Streams is a fully managed AWS service that you can use to stream live video from devices to the AWS Cloud, or build applications for real-time video processing or batch-oriented video analytics.
Kinesis Video Streams isn't just storage for video data. You can use it to watch your video streams in real time as they are received in the cloud.
You can use Kinesis Video Streams to capture massive amounts of live video data from millions of sources, including smartphones, security cameras, webcams, cameras embedded in cars, drones, andother sources.
You can also send non-video time-serialized data such as audio data, thermal imagery, depth data, RADAR data, and use kinesis to process these at a later Time.
you can stream video from a computer's webcam using the GStreamer  library, or from a camera on your network using RTSP.
You can also configure your Kinesis video stream to durably store media data for the specified retention period.
Kinesis Video Streams automatically stores this data and encrypts it at rest.
--> logs from mobile applications - logs from e-commers purchases - information from social media - satellite data - audio - video - spy cams - security cams etc;

10. AWS LAKE FORMATION :
The data lake is your persistent data that is stored in Amazon S3 and managed by Lake Formation using a Data Catalog.
The Data Catalog is your persistent metadata store. It is a managed service that lets you store, annotate, and share metadata in the AWS Cloud.
Metadata about data sources and targets is in the form of databases and tables.
AWS Lake Formation is a fully managed service that makes it easier for you to build, secure, and manage data lakes.
Lake Formation simplifies and automates many of the complex manual steps that are usually required to create data lakes.
These steps include collecting, cleansing, moving, and cataloging data, and securely making that data available for analytics and machine learning.
You point Lake Formation at your data sources, and Lake Formation crawls those sources and moves the data into your new Amazon Simple Storage Service (Amazon S3) data lake.
After the data is securely stored in the data lake, users can access the data through their choice of analytics services, including Amazon Athena, Amazon Redshift, and Amazon EMR.

11. AMAZON  MSK : Managed Streaming for Apache Kafka
Amazon Managed Streaming for Apache Kafka (Amazon MSK) is a fully managed service that enables you to build and run applications that use Apache Kafka to process streaming data.
Amazon MSK provides the control-plane operations, such as those for creating, updating, and deleting clusters.
It lets you use Apache Kafka data-plane operations, such as those for producing and consuming data. It runs open-source versions of Apache Kafka.

12. AMAZON QUICKSIGHT : https://www.youtube.com/watch?v=2V1bHRLRG-w&t=8s
Amazon QuickSight is a cloud-scale business intelligence (BI) service that you can use to deliver easy-to-understand insights to the people who you work with, wherever they are.
It connects to your data in the cloud and combines data from many different sources.
In a single data dashboard, QuickSight can include AWS data, third-party data, big data, spreadsheet data, SaaS data, B2B data, and more.
Securely push these dashboards to customers. Used to forecast future results and take decisions.

13. AMAZON REDSHIFT : https://www.youtube.com/watch?v=_qKm6o1zK3U&t=9s
Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. An Amazon Redshift data warehouse is a collection of computing resources called nodes, which are organized into a group called a cluster.
Each cluster runs an Amazon Redshift engine and contains one or more databases.
Redshift lets you easily save the results of your queries back to your S3 data lake using open formats, like Apache Parquet, so that you can do additional analytics from other analytics services like Amazon EMR, Amazon Athena, and Amazon SageMaker.




##################################################################################################################
##################################################################################################################
COMPUTE  :
##################################################################################################################
##################################################################################################################

1. ELASTIC COMPUTE CLOUD :  < Has a separate detailed chapter >
Amazon Elastic Compute Cloud (Amazon EC2) provides scalable computing capacity in the Amazon Web Services (AWS) Cloud.
Using Amazon EC2 eliminates your need to invest in hardware up front, so you can develop and deploy applications faster.
You can use Amazon EC2 to launch as many or as few virtual servers as you need, configure security and networking, and manage storage.
Amazon EC2 enables you to scale up or down to handle changes in requirements or spikes in popularity, reducing your need to forecast traffic.

2. AWS BATCH : https://www.youtube.com/watch?v=j_iI1DzSi5g      &&   https://www.youtube.com/watch?v=T4aAWrGHmxQ&t=29s
AWS Batch enables you to run batch computing workloads on the AWS Cloud.
Batch computing is a common way for developers, scientists, and engineers to access large amounts of compute resources.
AWS Batch removes the undifferentiated heavy lifting of configuring and managing the required infrastructure.
As a fully managed service, AWS Batch helps you to run batch computing workloads of any scale.
AWS Batch automatically provisions compute resources and optimizes the workload distribution based on the quantity and scale of the workloads.
With AWS Batch, there is no need to install or manage batch computing software, which allows you to focus on analysing results and solving problems.
After a compute environment is up and associated with a job queue, you can define job definitions that specify which Docker container images to run your jobs.
  --> Break work into bathes and tell AWS which batch needs which resources are required and when to execute a batch

3. AWS ELASTI BEANSTALK :  < Has a separate detailed chapter > https://www.youtube.com/watch?v=SrwxAScdyT0&t=28s
--> Focus on your code --> Write it --> Upload it -->  AWS takes care of required resources .
With AWS Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without worrying about the infrastructure that runs those applications.
AWS Elastic Beanstalk reduces management complexity without restricting choice or control.
You simply upload your application, and AWS Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.

4. AMAZON EC2 IMAGE BUILDER : https://www.youtube.com/watch?v=K5d2VdByohs&t=151s
It's a fully-managed AWS service that makes it easier to automate the creation, management, and deployment of customized, secure, and up-to-date “golden” server images that are pre-installed and pre-configured with software and settings to meet specific IT standards.
Crete a custom image based on required parameters and share the AMI across accounts or for instances in your account .

5. AWS LAMBDA :  < Has a separate detailed chapter >
--> Do something in response to events such as an api call / SNS / a data change in S3 /etc ;
With AWS Lambda, you can run code without provisioning or managing servers.
You pay only for the compute time that you consume—there’s no charge when your code isn’t running.
You can run code for virtually any type of application or backend service—all with zero administration.
Just upload your code and Lambda takes care of everything required to run and scale your code with high availability.
You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app.

6. AWS LAUNCH WIZARD :
--> Used by enterprise applications .
AWS Launch Wizard reduces the time it takes to deploy application and domain-controller solutions to the cloud by providing easy step-by-step guidance.
You input your application or domain controller requirements, and AWS Launch Wizard identifies the right AWS resources to deploy and run your solution.
AWS Launch Wizard provides an estimated cost of deployment, and gives you the ability to modify your resources and instantly view the updated cost assessment.
When you approve, AWS Launch Wizard provisions and configures the selected resources in a few hours to create fully-functioning, production-ready applications or domain controllers. It also creates custom AWS CloudFormation templates, which can be reused and customized for subsequent deployments.

7. AMAZON LIGHT SAIL : https://www.youtube.com/watch?v=wzhTAwRbdXw
--> Deploying a word press site etc ;
Amazon Lightsail helps developers get started using AWS to build websites or web applications.
It includes the features that you need to launch your project: instances (virtual private servers), managed databases, SSD-based block storage, static IP addresses, load balancers, content delivery network (CDN) distributions, DNS management of registered domains, and snapshots (backups).
These features are all available for a low, predictable monthly price.

8. AWS OUTPOSTS : https://www.youtube.com/watch?v=ppG2FFB0mMQ&t=9s
--> Even though we can use cloud , some applications still need to be on premises for latency issues . Hence OUTPOSTS.
    So instead of changing applications to meet both cloud and on premises apps , we can use same API's to access resources in both.
    AWS Technician comes and set up all the resources needed to connect resources in cloud and resources in on-premises.
An Outpost is a pool of AWS compute and storage capacity deployed at a customer site.
AWS Outposts brings native AWS services, infrastructure, and operating models to virtually any data center, co-location space, or on-premises facility.
You can use the same services, tools, and partner solutions to develop for the cloud and on premises .

9. AWS PARALLEL CLUSTER : HPC // 1000's of CPU or GPU.   https://www.youtube.com/watch?v=r4RxT-IMtFY
AWS Parallel Cluster is an AWS supported open source cluster management tool that helps you to deploy and manage high performance computing (HPC) clusters in the AWS Cloud.
You can use AWSParallelCluster with batch schedulers, such as AWS Batch and Slurm.
AWS Parallel Cluster facilitates quick start proof of concept deployments and production deployments.
You can also build higher level workflows, such as a genomics portal that automates an entire DNA sequencing workflow, on top of AWSParallelCluster.

10. AWS SAM : [ SERVERLESS APPLICATION MODEL ]
The AWS Serverless Application Model (AWS SAM) is an open-source framework that you can use to buildserverless applications on AWS.
You can use AWS SAM to define your serverless applications.
It is an extension of CLOUD FORMATION

11. AWS SERVERLESS APPLICATION REPOSITORY :
The AWS Serverless Application Repository is a managed repository for serverless applications.
It enables teams, organizations, and individual developers to find, deploy, publish, share, store, and easily assemble serverless architectures.
Using SAM from above , we can publish and deploy applications to the public or to our team.

12. AWS WAVE LENGTH : To fully utilize 5G capabilities . // https://www.youtube.com/watch?v=EhMqwPqPzcY&t=6s
AWS Wavelength allows developers to build applications that deliver ultra-low latencies to mobile devices and end users.
Wavelength deploys standard AWS compute and storage services to the edge of telecommunication carriers' 5G networks.
Developers can extend an Amazon Virtual Private Cloud (VPC) to one or more Wavelength Zones.
Then use AWS resources like Amazon Elastic Compute Cloud (EC2) instances to run applications that require ultra-low latency and a connection to AWS services in the Region.
To help 5G --> Gaming experience - smart cities - robotics - autonomous driving cars



##################################################################################################################
##################################################################################################################
CONTAINERS   :
##################################################################################################################
##################################################################################################################

// DOCKER FILE  is a text document that contains commands that are used to assemble an image.
   We can use any command that call on the command line.
   Docker builds images automatically by reading the instructions from the Dockerfile.

    $ docker build  /path/to/a/Dockerfile  --> To build an image.

// DOCKER image is a read-only template with instructions for creating a Docker container.
   A docker image is described in text file called a Dockerfile, which has a simple, well-defined syntax.

// Docker container is a running instance of an image.
   You can use Command Line Interface (CLI) commands to run, start, stop, move, or delete a container.
   You can also provide configuration for the network and environment variables.
   Docker container is an isolated and secure application platform, but it can share and access to resources running in a different host or container.

// DOCKER packages software into standardized units called CONTAINERS .
   They have everything your software needs to run including Libraries , system tools , code and run time .
   It lets you quickly deploy and scale applications into any environment and know your code will run .

    $ docker run hello-world   // $ docker run <image> --> To create a container from an image and run it.
    https://www.javatpoint.com/docker-java-example

1. AMAZON ECR :  [ Amazon Elastic Container Registry ] // https://www.youtube.com/watch?v=H73uX0TOX9g&t=2s
It is a fully managed Docker container registry that makes it easy for developers to store, manage, and deploy DOCKER CONTAINER IMAGES.
Supports private container image repositories with resource-based permissions using AWS IAM. This is so that specified users or Amazon EC2 instances can access your container repositories and images.
Sports public container image repositories as well.
A repository is where you store your Docker or Open Container Initiative (OCI) images in Amazon ECR.
Each time you push or pull an image from Amazon ECR, you specify the repository and the registry location which informs where to push the image to or where to pull it from.

// Once an image is registered in the ECR , we can run that image as a container in the ECS service. -- ECS is a logical group of EC2 instances.
   ECS CLUSTER is a logical group of EC2 instances that you can place containers into .
   Ec2 instances can be of different configurations , types , and in diff. AZ's

2.AMAZON ECS : [ Amazon Elastic Container Service ] // https://www.youtube.com/watch?v=zBqjh61QcB4&t=4s && https://www.youtube.com/watch?v=eq4wL2MiNqo
Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast container management service that makes it easy to run, stop, and manage containers on a cluster.
Amazon ECS enables you to launch and stop your container-based applications by using simple API calls.
You can create Amazon ECS clusters within a new or existing VPC.
After a cluster is up and running, you can create task definitions that define which container images run across your clusters.
Your task definitions are used to run tasks or create services. Container images are stored in and pulled from container registries, for example, the Amazon Elastic Container Registry.

To prepare your application to run on Amazon ECS, you must create a task definition.
The task definition is a text file (in JSON format) that describes one or more containers (up to a maximum of ten) that form your application.
The task definition can be thought of as a blueprint for your application. It specifies various parameters for your application.
For example, these parameters can be used to indicate which containers should be used, which ports should be opened for your application, and what data volumes should be used with the containers in the task.
The specific parameters available for your task definition depend on the needs of your specific application.

A task is the instantiation of a task definition within a cluster.
After you have created a task definition for your application within Amazon ECS, you can specify the number of tasks to run on your cluster.
The Amazon ECS task scheduler is responsible for placing tasks within your cluster. There are several different scheduling options available.

// ECS AGENT manages the state of containers on an EC2 instance.
   Manages how ECS communicates with the docker daemon on the ec2.
   Is present on every ec2 instance.
   Is included with an ECS-Optimised Amazon Machine Image - AMI

// KUBERNETIS also known as K8s, is an open-source system for automating deployment, scaling, and management of containerized applications.
   It groups containers that make up an application into logical units for easy management and discovery.

3. AMAZON EKS : [ Amazon Elastic Kubernetes Service  ]
It s a managed service that you can use to run Kubernetes on AWS without needing to install, operate, and maintain your own Kubernetes control plane or nodes.
Kubernetes is an open-source system for automating the deployment, scaling, and management of containerized applications.
Amazon EKS automatically detects and replaces unhealthy control plane instances, and it provides automated version upgrades and patching for them.
Amazon EKS runs up-to-date versions of the open-source Kubernetes software, so you can use all of the existing plugins and tooling from the Kubernetes community.

4. AWS FARGATE :
AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS).
Fargate makes it easy for you to focus on building your applications.
Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design.
Fargate allocates the right amount of compute, eliminating the need to choose instances and scale cluster capacity.
You only pay for the resources required to run your containers, so there is no over-provisioning and paying for additional servers.
Fargate runs each task or pod in its own kernel providing the tasks and pods their own isolated compute environment.
This enables your application to have workload isolation and improved security by design.
This is why customers such as Vanguard, Accenture, Foursquare, and Ancestry have chosen to run their mission critical applications on Fargate.

5. AWS APP2CONTAINER :
It is a command-line tool for modernizing .NET and Java applications into containerized applications.
Using A2C simplifies your migration tasks by performing inventory and analysis of your existing applications, creating Docker containers that include your application dependencies, and generating deployment templates based on AWS best practices with known values filled in for you.
After you have reviewed your templates, A2C helps you register your containers to Amazon ECR, deploy to Amazon ECS or Amazon EKS, and build CI/CD pipelines using AWS CodeStar.
It is also a command line tool to help you lift and shift applications that run in your on-premises data centers or on virtual machines, so that they run in containers that are managed by Amazon ECS or Amazon EKS. Thus providing a step towards modernization .



##################################################################################################################
##################################################################################################################
STORAGE   :
##################################################################################################################
##################################################################################################################

1. AMAZON SIMPLE STORAGE SERVICE - S3 :  < Has a separate detailed chapter >
--> Has 11 9's of durability . 99.999999999
It is storage for the internet. You can use Amazon S3 to store and retrieve any amount of data at any time, from anywhere on the web.
You can accomplish these tasks using the simple and intuitive web interface of the AWS Management Console.
A bucket is a container for objects stored in Amazon S3. Every object is contained in a bucket.

2. AWS BACKUP : https://www.youtube.com/watch?v=QDiXzFx2iMU&t=17s
AWS Backup is a fully managed backup service that makes it easy to centralize and automate the backup of data across AWS services in the cloud as well as on premises [ uses AWS STORAGE GATEWAY for on premisis].
Using AWS Backup, you can configure backup policies and monitor backup activity for your AWS resources in one place.
AWS Backup automates and consolidates backup tasks that were previously performed service-by-service, and removes the need to create custom scripts and manual processes.
It provides a fully managed backup service and a policy-based backup solution .
These features include Amazon Elastic Block Store (Amazon EBS) snapshots, Amazon Relational Database Service (Amazon RDS)snapshots, Amazon DynamoDB backups, AWS Storage Gateway snapshots, and others.
AWS Backup implements its backup features using the existing capabilities of these AWS services.
You can write backup PLANS to tell when to back up and when to move backup to Glacier etc;

3. AMAZON ELASTIC BLOCK STORE - EBS :  < Has a separate detailed chapter > // https://www.youtube.com/watch?v=77qLAl-lRpo
High performance and low latency block storage - has 4 types.
Amazon Elastic Block Store (Amazon EBS) is a web service that provides block level storage volumes for use with EC2 instances.
EBS volumes are highly available and reliable storage volumes that can be attached to any running instance and used like a hard drive.

4. AMAZON ELASTIC FILE SYSTEM - EFS : -> Its a Cloud File  https://www.youtube.com/watch?v=6ZIPBC78U0s&t=8s
It provides file storage for your Amazon EC2 instances.
With Amazon EFS, you can create a file system, mount the file system on your EC2 instances, and then read and write data from your EC2 instances to and from your file system.
It provides a simple, scalable, fully managed elastic NFS filesystem for use with AWS Cloud services and on-premises resources.
Amazon EFS has a simple web services interface that allows you to create and configure file systems quickly and easily.
Multiple Amazon EC2instances can access an Amazon EFS file system at the same time, providing a common data source for workloads and applications running on more than one instance or server.
Using Amazon EFS with Microsoft Windows–based Amazon EC2 instances is not supported.

                        EC2-a --
                        EC2-b   | <---------->  |||||||||  -> EFS
                        EC2-c --       NFS
            So multiple instances can access NFS at the same time using a standard NFSv4 Protocol .
            Once EFS is create d, we can mount EC2 instances on EFS.
            Useful when application runs on multiple EC2.

Whenyou first create your file system, there is only one root directory at /.
By default, only the root user (UID0) has read-write-execute permissions. For other users to modify the file system, the root user must explicitly grant them access.
You use EFS access points to provision directories that are writable from a specific application

// EFS for Linux
// FSx for Windows

5. AMAZON FSx : https://www.youtube.com/watch?v=4v08-CzjH1U
Amazon FSx provides fully managed third-party file systems with the native compatibility and feature sets for workloads such as Microsoft Windows–based storage, high-performance computing, machine learning, and electronic design automation.
Amazon FSx supports two file system types: Lustre and Windows File Server.
With file storage on Amazon FSx, the code, applications, and tools that Windows developers and administrators use today can continue to work unchanged.
Windows applications and workloads ideal for Amazon FSx include business applications, home directories, web serving, content management, data analytics, software build setups, and media processing workloads.

6. AMAZON SNOW FAMILY : < Has a separate detailed chapter - Storage_s3 >
 -> Snow cone        - https://www.youtube.com/watch?v=X_8LM7E_hiE      -- 8 TB storage   --> 1 SMALL BOX [ uses opshub application for data transfer ]
    Snow Ball        - https://www.youtube.com/watch?v=9uc2DSZ1wL8&t=9s -- 80 TB storage  --> 1 SUITCASE
    Snow Ball edge   - https://www.youtube.com/watch?v=bxSD1Nha2k8      -- 100 TB storage --> 1 SUITCASE  [ Embedded Ec2 - Lambda for running jobs in remote areas like ships , hills for an immediate results. ]
    Snow Mobile      - https://www.youtube.com/watch?v=8vQmTZTq7nw      -- 1 Exabyte      --> 1 Truck

   1 Exabyte = 1000 petabytes
   Snow ball can be connected in series to have a Petabyte's storage  = 1 million GB = 1024 Terabytes

7. AMAZON STORAGE GATEWAY : < Has a separate detailed chapter - Storage_s3 > -- https://www.youtube.com/watch?v=DPyc0q4MYsM -- https://www.youtube.com/watch?v=Spzdj1NUJbA -- https://www.youtube.com/watch?v=2I4CKdNESoQ&t=8s --
--> HYBRID CLOUD STORAGE SERVICE WITH A LOCAL CACHE . -- FILE GATEWAY -- VOLUME GATEWAY -- TAPE GATEWAY .
AWS Storage Gateway is a service that connects an on-premises software appliance with cloud-based storage to provide seamless and secure integration between your on-premises IT environment and the AWS storage infrastructure in the cloud.
Securely takes data from on premises data centre and uploads in S3 using SSL. We can get back data when ever we need it , for example if a hard disk crashed in on-premisi then we need to restore it back .
Storage gateway keeps regular backups from S3 so that it can restore to on-premises when needed.

The above process is needed until you are ready to move completely to cloud .
Slowly we can also launch an EC2 and attach an EBS with data from S3 and migrate to cloud directly.



##################################################################################################################
##################################################################################################################
DATABASE   :
##################################################################################################################
##################################################################################################################
